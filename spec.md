Project Goal: An autonomous agent that performs deep web research and generates cited reports locally. Core Components:

Orchestrator: LangGraph (to manage the research loop).

The Brain: Llama-3-8B (via Ollama) running on M4 Pro.

Tools: Crawl4AI (for lightning-fast markdown extraction) + DuckDuckGo Search.

State Management: Tracking research "Gaps" and "Findings."

## Implementation Details

### 1. Environment Configuration
* **Hardware:** MacBook Pro M4 Pro (optimized for Metal-accelerated inference).
* **LLM Server:** Ollama running Llama-3-8B.
* **Scraper:** Crawl4AI (`AsyncWebCrawler`) configured for markdown output to minimize token usage and bypass high-latency rendering.
* **Search Engine:** DuckDuckGo Search API (via LangChain Community tools).

### 2. State Management Schema
The agent maintains a `TypedDict` state to ensure structured transitions and memory persistence:
* **`question`**: The original research objective or user prompt.
* **`search_queries`**: Current list of active search strings generated by the brain.
* **`findings`**: A collection of scraped facts, data points, and summarized context.
* **`gaps`**: Specifically identified missing information that requires further search iterations.
* **`iteration`**: A safety counter to prevent infinite loops (max 5 iterations).

### 3. Execution Graph (LangGraph)
The research process follows a directed cyclic graph (DCG) pattern:

1.  **Gap Analysis Node:** Llama-3 analyzes current `findings` against the `question` to identify what is still unknown (`gaps`).
2.  **Search Orchestrator Node:** Generates high-intent search queries for the top-priority gap.
3.  **Content Processor Node:** * Executes DuckDuckGo search.
    * Triggers `Crawl4AI` for the most relevant URLs.
    * Summarizes the raw markdown into a concise "Finding."
4.  **Conditional Router:** * If `gaps` are resolved or `iteration` limit reached → **Report Writer**.
    * If more info is needed → Loop back to **Gap Analysis**.

### 4. Output Generation
* **Report Writer Node:** Synthesizes the finalized `findings` into a professional markdown report.
* **Citations:** Every fact is mapped back to the source URL captured during the scraping phase to ensure 100% verifiability.